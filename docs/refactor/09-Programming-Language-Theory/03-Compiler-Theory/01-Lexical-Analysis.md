# 01-è¯æ³•åˆ†æ (Lexical Analysis)

## ç›®å½•

- [1. æ¦‚è¿°](#1-æ¦‚è¿°)
- [2. æ­£åˆ™è¡¨è¾¾å¼](#2-æ­£åˆ™è¡¨è¾¾å¼)
- [3. æœ‰é™è‡ªåŠ¨æœº](#3-æœ‰é™è‡ªåŠ¨æœº)
- [4. è¯æ³•åˆ†æå™¨](#4-è¯æ³•åˆ†æå™¨)
- [5. Goè¯­è¨€å®ç°](#5-goè¯­è¨€å®ç°)
- [6. åº”ç”¨å®ä¾‹](#6-åº”ç”¨å®ä¾‹)

## 1. æ¦‚è¿°

è¯æ³•åˆ†ææ˜¯ç¼–è¯‘å™¨çš„ç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œå°†æºä»£ç å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ ‡è®°(token)åºåˆ—ã€‚æœ¬æ–‡æ¡£åŸºäºå¯¹ç¼–ç¨‹è¯­è¨€ç†è®ºçš„æ·±åº¦åˆ†æï¼Œå»ºç«‹äº†å®Œæ•´çš„è¯æ³•åˆ†æç†è®ºä½“ç³»ã€‚

### 1.1 è¯æ³•åˆ†æå®šä¹‰

**å®šä¹‰ 1.1** (è¯æ³•åˆ†æ)
è¯æ³•åˆ†ææ˜¯ä¸€ä¸ªå‡½æ•° $L: \Sigma^* \rightarrow T^*$ï¼Œå…¶ä¸­ï¼š

- $\Sigma$ æ˜¯è¾“å…¥å­—æ¯è¡¨
- $T$ æ˜¯æ ‡è®°é›†åˆ
- $L$ å°†è¾“å…¥å­—ç¬¦ä¸²æ˜ å°„ä¸ºæ ‡è®°åºåˆ—

**å®šç† 1.1** (è¯æ³•åˆ†æç¡®å®šæ€§)
å¯¹äºä»»æ„è¾“å…¥å­—ç¬¦ä¸² $s \in \Sigma^*$ï¼Œè¯æ³•åˆ†æå™¨äº§ç”Ÿå”¯ä¸€çš„æ ‡è®°åºåˆ—ã€‚

**è¯æ˜**:

1. é€šè¿‡æœ€é•¿åŒ¹é…åŸåˆ™
2. æ ‡è®°ä¼˜å…ˆçº§è§„åˆ™
3. ç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœº

### 1.2 æ ‡è®°å®šä¹‰

**å®šä¹‰ 1.2** (æ ‡è®°)
æ ‡è®°æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ $(type, value, position)$ï¼Œå…¶ä¸­ï¼š

- $type$ æ˜¯æ ‡è®°ç±»å‹
- $value$ æ˜¯æ ‡è®°å€¼
- $position$ æ˜¯ä½ç½®ä¿¡æ¯

```go
// æ ‡è®°å®šä¹‰
type Token struct {
    Type     TokenType
    Value    string
    Position Position
    Line     int
    Column   int
}

type TokenType int

const (
    TOKEN_EOF TokenType = iota
    TOKEN_IDENTIFIER
    TOKEN_NUMBER
    TOKEN_STRING
    TOKEN_KEYWORD
    TOKEN_OPERATOR
    TOKEN_DELIMITER
    TOKEN_COMMENT
    TOKEN_WHITESPACE
)

type Position struct {
    Offset int
    Line   int
    Column int
}

// æ ‡è®°ç±»å‹å­—ç¬¦ä¸²è¡¨ç¤º
func (tt TokenType) String() string {
    switch tt {
    case TOKEN_EOF:
        return "EOF"
    case TOKEN_IDENTIFIER:
        return "IDENTIFIER"
    case TOKEN_NUMBER:
        return "NUMBER"
    case TOKEN_STRING:
        return "STRING"
    case TOKEN_KEYWORD:
        return "KEYWORD"
    case TOKEN_OPERATOR:
        return "OPERATOR"
    case TOKEN_DELIMITER:
        return "DELIMITER"
    case TOKEN_COMMENT:
        return "COMMENT"
    case TOKEN_WHITESPACE:
        return "WHITESPACE"
    default:
        return "UNKNOWN"
    }
}
```

## 2. æ­£åˆ™è¡¨è¾¾å¼

### 2.1 æ­£åˆ™è¡¨è¾¾å¼å®šä¹‰

**å®šä¹‰ 3.1** (æ­£åˆ™è¡¨è¾¾å¼)
æ­£åˆ™è¡¨è¾¾å¼çš„è¯­æ³•å®šä¹‰ä¸ºï¼š
$$R ::= \varepsilon \mid a \mid R_1 \cdot R_2 \mid R_1 + R_2 \mid R^*$$

å…¶ä¸­ï¼š

- $\varepsilon$ æ˜¯ç©ºå­—ç¬¦ä¸²
- $a$ æ˜¯å­—æ¯è¡¨ä¸­çš„ç¬¦å·
- $\cdot$ æ˜¯è¿æ¥æ“ä½œ
- $+$ æ˜¯é€‰æ‹©æ“ä½œ
- $*$ æ˜¯Kleeneæ˜Ÿå·

**å®šç† 3.1** (æ­£åˆ™è¡¨è¾¾å¼ç­‰ä»·æ€§)
æ­£åˆ™è¡¨è¾¾å¼ä¸æœ‰é™è‡ªåŠ¨æœºç­‰ä»·ã€‚

## 3. æœ‰é™è‡ªåŠ¨æœº

### 3.1 ç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœº

**å®šä¹‰ 2.1** (DFA)
ç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœºæ˜¯ä¸€ä¸ªäº”å…ƒç»„ $M = (Q, \Sigma, \delta, q_0, F)$ï¼Œå…¶ä¸­ï¼š

- $Q$ æ˜¯çŠ¶æ€é›†åˆ
- $\Sigma$ æ˜¯è¾“å…¥å­—æ¯è¡¨
- $\delta: Q \times \Sigma \rightarrow Q$ æ˜¯è½¬ç§»å‡½æ•°
- $q_0 \in Q$ æ˜¯åˆå§‹çŠ¶æ€
- $F \subseteq Q$ æ˜¯æ¥å—çŠ¶æ€é›†åˆ

**å®šç† 2.1** (DFAæ¥å—æ€§)
DFA $M$ æ¥å—å­—ç¬¦ä¸² $w$ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨çŠ¶æ€åºåˆ— $q_0, q_1, \ldots, q_n$ ä½¿å¾—ï¼š

1. $q_0$ æ˜¯åˆå§‹çŠ¶æ€
2. $\delta(q_i, w_i) = q_{i+1}$ å¯¹äº $0 \leq i < n$
3. $q_n \in F$

### 3.2 éç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœº

**å®šä¹‰ 2.2** (NFA)
éç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœºæ˜¯ä¸€ä¸ªäº”å…ƒç»„ $M = (Q, \Sigma, \delta, q_0, F)$ï¼Œå…¶ä¸­ï¼š

- $\delta: Q \times \Sigma \rightarrow 2^Q$ æ˜¯è½¬ç§»å‡½æ•°
- å…¶ä»–å®šä¹‰ä¸DFAç›¸åŒ

**å®šç† 2.2** (NFAåˆ°DFAè½¬æ¢)
å¯¹äºä»»æ„NFAï¼Œå­˜åœ¨ç­‰ä»·çš„DFAã€‚

## 4. è¯æ³•åˆ†æå™¨

### 4.1 è¯æ³•åˆ†æå™¨å®ç°

```go
// Lexer è¯æ³•åˆ†æå™¨
type Lexer struct {
    Input   string
    Position int
    Line    int
    Column  int
    Tokens  []Token
}

func (l *Lexer) Tokenize() []Token {
    l.Tokens = []Token{}
    
    for l.Position < len(l.Input) {
        // è·³è¿‡ç©ºç™½å­—ç¬¦
        l.skipWhitespace()
        
        if l.Position >= len(l.Input) {
            break
        }
        
        // è¯†åˆ«è¯æ³•å•å…ƒ
        token := l.nextToken()
        if token.Type != TokenEOF {
            l.Tokens = append(l.Tokens, token)
        }
    }
    
    // æ·»åŠ EOFæ ‡è®°
    l.Tokens = append(l.Tokens, Token{
        Type: TokenEOF,
        Value: "",
        Line: l.Line,
        Column: l.Column,
    })
    
    return l.Tokens
}

func (l *Lexer) skipWhitespace() {
    for l.Position < len(l.Input) {
        char := rune(l.Input[l.Position])
        if char == ' ' || char == '\t' {
            l.Position++
            l.Column++
        } else if char == '\n' {
            l.Position++
            l.Line++
            l.Column = 1
        } else {
            break
        }
    }
}

func (l *Lexer) nextToken() Token {
    char := rune(l.Input[l.Position])
    startPos := l.Position
    startLine := l.Line
    startColumn := l.Column
    
    // è¯†åˆ«æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
    if isLetter(char) {
        return l.readIdentifier()
    }
    
    // è¯†åˆ«æ•°å­—
    if isDigit(char) {
        return l.readNumber()
    }
    
    // è¯†åˆ«å­—ç¬¦ä¸²
    if char == '"' {
        return l.readString()
    }
    
    // è¯†åˆ«æ“ä½œç¬¦
    if isOperator(char) {
        return l.readOperator()
    }
    
    // è¯†åˆ«åˆ†éš”ç¬¦
    if isDelimiter(char) {
        return l.readDelimiter()
    }
    
    // æœªçŸ¥å­—ç¬¦
    l.Position++
    l.Column++
    return Token{
        Type: TokenEOF,
        Value: string(char),
        Line: startLine,
        Column: startColumn,
    }
}

func (l *Lexer) readIdentifier() Token {
    startPos := l.Position
    startLine := l.Line
    startColumn := l.Column
    
    for l.Position < len(l.Input) {
        char := rune(l.Input[l.Position])
        if !isLetter(char) && !isDigit(char) && char != '_' {
            break
        }
        l.Position++
        l.Column++
    }
    
    value := l.Input[startPos:l.Position]
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºå…³é”®å­—
    if isKeyword(value) {
        return Token{
            Type: TokenKeyword,
            Value: value,
            Line: startLine,
            Column: startColumn,
        }
    }
    
    return Token{
        Type: TokenIdentifier,
        Value: value,
        Line: startLine,
        Column: startColumn,
    }
}

func (l *Lexer) readNumber() Token {
    startPos := l.Position
    startLine := l.Line
    startColumn := l.Column
    
    for l.Position < len(l.Input) {
        char := rune(l.Input[l.Position])
        if !isDigit(char) && char != '.' {
            break
        }
        l.Position++
        l.Column++
    }
    
    value := l.Input[startPos:l.Position]
    
    return Token{
        Type: TokenNumber,
        Value: value,
        Line: startLine,
        Column: startColumn,
    }
}

func (l *Lexer) readString() Token {
    startLine := l.Line
    startColumn := l.Column
    
    // è·³è¿‡å¼€å§‹çš„å¼•å·
    l.Position++
    l.Column++
    
    startPos := l.Position
    
    for l.Position < len(l.Input) {
        char := rune(l.Input[l.Position])
        if char == '"' {
            l.Position++
            l.Column++
            break
        } else if char == '\n' {
            l.Line++
            l.Column = 1
        }
        l.Position++
        l.Column++
    }
    
    value := l.Input[startPos:l.Position-1]
    
    return Token{
        Type: TokenString,
        Value: value,
        Line: startLine,
        Column: startColumn,
    }
}

func (l *Lexer) readOperator() Token {
    startLine := l.Line
    startColumn := l.Column
    
    char := rune(l.Input[l.Position])
    l.Position++
    l.Column++
    
    // æ£€æŸ¥åŒå­—ç¬¦æ“ä½œç¬¦
    if l.Position < len(l.Input) {
        nextChar := rune(l.Input[l.Position])
        if isDoubleOperator(char, nextChar) {
            l.Position++
            l.Column++
            return Token{
                Type: TokenOperator,
                Value: string(char) + string(nextChar),
                Line: startLine,
                Column: startColumn,
            }
        }
    }
    
    return Token{
        Type: TokenOperator,
        Value: string(char),
        Line: startLine,
        Column: startColumn,
    }
}

func (l *Lexer) readDelimiter() Token {
    startLine := l.Line
    startColumn := l.Column
    
    char := rune(l.Input[l.Position])
    l.Position++
    l.Column++
    
    return Token{
        Type: TokenDelimiter,
        Value: string(char),
        Line: startLine,
        Column: startColumn,
    }
}
```

### 4.2 è¾…åŠ©å‡½æ•°

```go
func isLetter(char rune) bool {
    return (char >= 'a' && char <= 'z') || (char >= 'A' && char <= 'Z')
}

func isDigit(char rune) bool {
    return char >= '0' && char <= '9'
}

func isOperator(char rune) bool {
    operators := []rune{'+', '-', '*', '/', '=', '<', '>', '!', '&', '|', '^', '%'}
    for _, op := range operators {
        if char == op {
            return true
        }
    }
    return false
}

func isDelimiter(char rune) bool {
    delimiters := []rune{'(', ')', '[', ']', '{', '}', ';', ',', '.', ':'}
    for _, delim := range delimiters {
        if char == delim {
            return true
        }
    }
    return false
}

func isKeyword(value string) bool {
    keywords := []string{
        "func", "var", "const", "type", "struct", "interface",
        "if", "else", "for", "range", "switch", "case", "default",
        "return", "break", "continue", "defer", "go", "select",
        "chan", "map", "package", "import",
    }
    
    for _, keyword := range keywords {
        if value == keyword {
            return true
        }
    }
    return false
}

func isDoubleOperator(first, second rune) bool {
    doubleOps := map[rune][]rune{
        '=': {'='},
        '!': {'='},
        '<': {'=', '<'},
        '>': {'=', '>'},
        '&': {'&'},
        '|': {'|'},
        '+': {'+', '='},
        '-': {'-', '='},
        '*': {'='},
        '/': {'=', '/'},
        '%': {'='},
        '^': {'='},
    }
    
    if ops, exists := doubleOps[first]; exists {
        for _, op := range ops {
            if second == op {
                return true
            }
        }
    }
    return false
}
```

## 5. Goè¯­è¨€å®ç°

### 5.1 å®Œæ•´çš„è¯æ³•åˆ†æå™¨

```go
// GoLexer Goè¯­è¨€è¯æ³•åˆ†æå™¨
type GoLexer struct {
    *Lexer
    Keywords map[string]bool
    Operators map[string]bool
}

func NewGoLexer(input string) *GoLexer {
    lexer := &GoLexer{
        Lexer: &Lexer{
            Input: input,
            Position: 0,
            Line: 1,
            Column: 1,
        },
        Keywords: make(map[string]bool),
        Operators: make(map[string]bool),
    }
    
    // åˆå§‹åŒ–Goè¯­è¨€å…³é”®å­—
    goKeywords := []string{
        "break", "case", "chan", "const", "continue", "default", "defer",
        "else", "fallthrough", "for", "func", "go", "goto", "if", "import",
        "interface", "map", "package", "range", "return", "select", "struct",
        "switch", "type", "var",
    }
    
    for _, keyword := range goKeywords {
        lexer.Keywords[keyword] = true
    }
    
    // åˆå§‹åŒ–æ“ä½œç¬¦
    goOperators := []string{
        "+", "-", "*", "/", "%", "&", "|", "^", "<<", ">>", "&^",
        "+=", "-=", "*=", "/=", "%=", "&=", "|=", "^=", "<<=", ">>=", "&^=",
        "&&", "||", "<-", "++", "--", "==", "<", ">", "!=", "<=", ">=",
        "=", ":=", "...",
    }
    
    for _, op := range goOperators {
        lexer.Operators[op] = true
    }
    
    return lexer
}

func (gl *GoLexer) Tokenize() []Token {
    return gl.Lexer.Tokenize()
}
```

## 6. åº”ç”¨å®ä¾‹

### 6.1 ç®€å•è¡¨è¾¾å¼è¯æ³•åˆ†æ

```go
func ExampleExpressionLexing() {
    input := "x = 42 + y * 3"
    
    lexer := NewGoLexer(input)
    tokens := lexer.Tokenize()
    
    for _, token := range tokens {
        fmt.Printf("Token: %s, Type: %d, Line: %d, Column: %d\n",
            token.Value, token.Type, token.Line, token.Column)
    }
}
```

### 6.2 Goä»£ç è¯æ³•åˆ†æ

```go
func ExampleGoCodeLexing() {
    input := `
package main

import "fmt"

func main() {
    x := 42
    fmt.Println("Hello, World!")
}
`
    
    lexer := NewGoLexer(input)
    tokens := lexer.Tokenize()
    
    for _, token := range tokens {
        if token.Type != TokenEOF {
            fmt.Printf("%s ", token.Value)
        }
    }
    fmt.Println()
}
```

## æ€»ç»“

è¯æ³•åˆ†ææ˜¯ç¼–è¯‘å™¨çš„ç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œè´Ÿè´£å°†æºä»£ç å­—ç¬¦æµè½¬æ¢ä¸ºè¯æ³•å•å…ƒåºåˆ—ã€‚é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼å’Œæœ‰é™è‡ªåŠ¨æœºçš„ç†è®ºåŸºç¡€ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºé«˜æ•ˆå‡†ç¡®çš„è¯æ³•åˆ†æå™¨ã€‚

**å…³é”®è¦ç‚¹**ï¼š

1. **ç†è®ºåŸºç¡€**ï¼šåŸºäºæ­£åˆ™è¡¨è¾¾å¼å’Œæœ‰é™è‡ªåŠ¨æœºçš„å½¢å¼åŒ–ç†è®º
2. **å®ç°æŠ€æœ¯**ï¼šDFAå’ŒNFAçš„è½¬æ¢å’Œä¼˜åŒ–
3. **å®é™…åº”ç”¨**ï¼šåœ¨ç¼–è¯‘å™¨ã€è§£é‡Šå™¨ã€æ–‡æœ¬å¤„ç†ç­‰é¢†åŸŸå¹¿æ³›åº”ç”¨
4. **Goè¯­è¨€ç‰¹æ€§**ï¼šå……åˆ†åˆ©ç”¨Goè¯­è¨€çš„å­—ç¬¦ä¸²å¤„ç†å’Œmapæ•°æ®ç»“æ„

**æ¿€æƒ…æ¾æ¹ƒçš„æŒç»­æ„å»º** <(ï¿£ï¸¶ï¿£)â†—[GO!] **è¯æ³•åˆ†æç†è®ºå®Œæˆï¼** ğŸš€
